{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# from networkx.algorithms.community import louvain_communities\n",
    "# def louvain(adj_matrix, num_clusters = 0):\n",
    "#     graph = nx.from_numpy_array(adj_matrix)\n",
    "#     comms = louvain_communities(graph)\n",
    "#     labels_ = np.zeros(graph.number_of_nodes(), dtype=int)\n",
    "#     for k, comm in enumerate(comms):\n",
    "#         for vertex in comm: \n",
    "#             labels_[vertex] = k\n",
    "#     return labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# import numpy.linalg as la\n",
    "# from sklearn.cluster import KMeans\n",
    "# import matplotlib.pyplot as plt \n",
    "# from scipy.sparse import csgraph\n",
    "# def spectral_clustering(adj_matrix, num_clusters = 0): \n",
    "#     D = np.diag(np.ravel(np.sum(adj_matrix,axis=1)))\n",
    "#     L = D - adj_matrix\n",
    "#     l, U = la.eigh(L)\n",
    "#     kmeans = KMeans(n_clusters=num_clusters).fit(U[:,1:num_clusters])\n",
    "#     labels_ = kmeans.labels_\n",
    "#     return labels_\n",
    "# def normalized_spectral_clustering(adj_matrix, num_clusters = 0): \n",
    "#     l, U = la.eigh(csgraph.laplacian(adj_matrix, normed=True))\n",
    "#     kmeans = KMeans(n_clusters=num_clusters).fit(U[:,1:num_clusters]) \n",
    "#     labels_ = kmeans.labels_\n",
    "#     return labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import tree \n",
    "import numpy as np\n",
    "def get_community_labels(G):\n",
    "    cc = list(nx.connected_components(G))\n",
    "    labels_ = np.zeros(G.number_of_nodes(), dtype=int)\n",
    "    for k, comm in enumerate(cc):\n",
    "        for label in comm: \n",
    "            labels_[label] = k\n",
    "    return labels_\n",
    "\n",
    "def get_community_labels_from_less_cc(G, num_clusters):\n",
    "    cc = list(nx.connected_components(G))\n",
    "    labels_ = np.zeros(G.number_of_nodes(), dtype=int)\n",
    "    for k, comm in enumerate(cc): \n",
    "        for label in comm:\n",
    "            labels_[label] = k\n",
    "    \n",
    "    return labels_\n",
    "\n",
    "def get_unique_thresholds(adj_matrix):\n",
    "    tvs = adj_matrix.copy()\n",
    "    tvs = tvs.reshape(tvs.shape[0] * tvs.shape[1])\n",
    "    tvs = np.sort(tvs)\n",
    "    tvs = np.unique(tvs)\n",
    "    return tvs\n",
    "\n",
    "def threshold_clustering(adj_matrix, num_clusters):\n",
    "    adj_matrix_ = adj_matrix.copy()\n",
    "    tvs = get_unique_thresholds(adj_matrix_)\n",
    "    k=0\n",
    "    for k in range(tvs.shape[0]):\n",
    "        adj_matrix_prev = adj_matrix_.copy()\n",
    "        adj_matrix_[adj_matrix_ < tvs[k]] = 0\n",
    "        G = nx.from_numpy_array(adj_matrix_)\n",
    "        num_components = nx.number_connected_components(G)\n",
    "        if num_components < num_clusters:\n",
    "            continue\n",
    "        elif num_components == num_clusters:\n",
    "            return get_community_labels(G)\n",
    "        else:\n",
    "            for i in range(adj_matrix_prev.shape[0]):\n",
    "                for j in range(adj_matrix_prev.shape[0]):\n",
    "                    if (adj_matrix_prev[i][j] < tvs[k] and adj_matrix_prev[i][j] != 0):\n",
    "                        adj_matrix_prev[i][j] = 0\n",
    "                        G = nx.from_numpy_array(adj_matrix_prev)\n",
    "                        num_components = nx.number_connected_components(G)\n",
    "                        if num_components == num_clusters:\n",
    "                            return get_community_labels(G)\n",
    "    for i in range(adj_matrix_.shape[0]):\n",
    "        for j in range(adj_matrix_.shape[0]):\n",
    "            if (adj_matrix_[i][j] != 0):\n",
    "                adj_matrix_[i][j] = 0\n",
    "                G = nx.from_numpy_array(adj_matrix_)\n",
    "                num_components = nx.number_connected_components(G)\n",
    "                if num_components == num_clusters:\n",
    "                    return get_community_labels(G)\n",
    "                \n",
    "    return np.arange(adj_matrix.shape[0])\n",
    "\n",
    "\n",
    "# def mst_cut_clustering(adj_matrix, num_clusters):\n",
    "#     G = nx.from_numpy_array(adj_matrix)\n",
    "#     mst = tree.maximum_spanning_edges(G, algorithm=\"kruskal\")\n",
    "#     edgelist = list(mst)\n",
    "#     edgelist.sort(key=lambda tup: tup[2]['weight'])\n",
    "#     cutted_mst = nx.from_edgelist(edgelist)\n",
    "#     to_cut = edgelist[0:num_clusters - 1] \n",
    "#     cutted_mst.remove_edges_from(to_cut)\n",
    "#     return get_community_labels(cutted_mst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "# from . import parallel\n",
    "\n",
    "# def fechner_corr(x,y):\n",
    "#     x_div = x - np.mean(x)\n",
    "#     y_div = y - np.mean(y)\n",
    "#     return np.sum(np.sign(x_div * y_div)) / x.shape[0], 0\n",
    "\n",
    "\n",
    "# Student's T random variable\n",
    "# def multivariate_t_rvs(m, S, n=1, df=3):\n",
    "#     '''\n",
    "#     generate random variables of multivariate t distribution Parameters\n",
    "#     ----------\n",
    "#     m : array_like\n",
    "#             mean of random variable, length determines dimension of random variable\n",
    "#         S : array_like\n",
    "#             square array of covariance  matrix\n",
    "#     [ ]:\n",
    "#     3\n",
    "#         df : int or float\n",
    "#             degrees of freedom\n",
    "#         n : int\n",
    "#             number of observations, return random array will be (n, len(m))\n",
    "#         Returns\n",
    "#         -------\n",
    "#     rvs : ndarray, (n, len(m))\n",
    "#         each row is an independent draw of a multivariate t distributed\n",
    "#         random variable\n",
    "#     '''\n",
    "#     m = np.asarray(m)\n",
    "#     d = len(m)\n",
    "#     if df == np.inf:\n",
    "#         x = np.ones(n)\n",
    "#     else:\n",
    "#         x = np.random.chisquare(df, n) / df\n",
    "#     z = np.random.multivariate_normal(np.zeros(d), S, (n,))\n",
    "#     return m + z/np.sqrt(x)[:,None] # same output format as random.multivariate_normal\n",
    "\n",
    "\n",
    "def get_mean_cov(num_clusters = 2, cluster_size = 50, r_in = 1, r_out = 0): \n",
    "    vertex_count = num_clusters * cluster_size\n",
    "    mean = np.zeros(vertex_count)\n",
    "    r_ins = np.full((cluster_size, cluster_size), r_in)\n",
    "    r_outs = np.full((cluster_size, cluster_size), r_out)\n",
    "    cov = np.block([[np.tile(r_outs,k),r_ins,np.tile(r_outs,num_clusters-k -1)] for k in range(num_clusters)])\n",
    "    np.fill_diagonal(cov,1)\n",
    "    return mean, cov\n",
    "\n",
    "\n",
    "def get_cor_from_cov(covariance):\n",
    "    v = np.sqrt(np.diag(covariance))\n",
    "    outer_v = np.outer(v, v)\n",
    "    correlation = covariance / outer_v\n",
    "    correlation[covariance == 0] = 0\n",
    "    return correlation\n",
    "\n",
    "def generate_samples_bag(mean, cov, bags = 10, sample_size = 50, distribution = np.random.multivariate_normal, **kwargs):\n",
    "    if distribution.__name__ == 'multivariate_t_rvs' and len(kwargs):\n",
    "        return np.hsplit(distribution(mean, cov, sample_size * bags, kwargs['df']).T, bags) \n",
    "    else:\n",
    "        return np.hsplit(distribution(mean, cov, sample_size * bags).T, bags)\n",
    "    \n",
    "\n",
    "#this function is required since networkx does not link vertices with zero weigth\n",
    "#TODO - remove this solutiuion as it slightly moves distribution if zero is in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_zero_weights_to_very_low(adj_matrixes, value = 1e-6):\n",
    "    adj_matrixes[adj_matrixes < value] = value\n",
    "    return adj_matrixes\n",
    "\n",
    "def get_corr_estimate(sample, corr_estimator = stats.pearsonr):\n",
    "    vertex_count = sample.shape[0]\n",
    "    corr_estimate = np.ones((vertex_count, vertex_count))\n",
    "    for i in range(vertex_count):\n",
    "        for j in range(i + 1, vertex_count):\n",
    "            corr, _ = corr_estimator(sample[i], sample[j])\n",
    "            corr = abs(corr)\n",
    "            corr_estimate[i][j] = corr\n",
    "            corr_estimate[j][i] = corr\n",
    "    return corr_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class corr_estimate_parallel(object):\n",
    "#     def __init__(self, samples_bags, corr_estimator, backend = 'threading'):\n",
    "#         self.samples_bags = samples_bags\n",
    "#         self.corr_estimator = corr_estimator\n",
    "#         self.backend = backend\n",
    "#     def get_estimations(self):\n",
    "#         indexes = [i for i in range(len(self.samples_bags))]\n",
    "#         estimations = parallel.For(indexes, backend = self.backend, progress=False)(self.get_estimate_bag)\n",
    "#         return estimations\n",
    "\n",
    "#     def get_estimate_bag(self, index):\n",
    "#         indexes = [(index, i) for i in range(len(self.samples_bags[index]))]\n",
    "#         return parallel.For(indexes, backend = self.backend, progress=False)(self._estimate_sample)\n",
    "\n",
    "\n",
    "#     def _estimate_sample(self, index):\n",
    "#         return set_zero_weights_to_very_low(get_corr_estimate(self.samples_bags[index[0]][index[1]], self.corr_estimator)) \n",
    "\n",
    "# # def get_true_graph():\n",
    "# #\n",
    "# # # # #\n",
    "# mean_covs = [get_mean_cov(num_clusters = num_clusters, cluster_size =␣ ↪cluster_size, r_in = rs[0][i], r_out = rs[1][i]) for i in range(rs.shape[1])]\n",
    "#      means = [mean_cov[0] for mean_cov in mean_covs]\n",
    "#      covs = [mean_cov[1] for mean_cov in mean_covs]\n",
    "#      true_graph = get_cor_from_cov(cov)\n",
    "#      return true_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import numpy.linalg as la\n",
    "import scipy.cluster.vq as vq\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import statistics\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.sparse import csgraph\n",
    "from scipy import stats\n",
    "from sklearn.metrics.cluster import rand_score\n",
    "#from sklearn.metrics import rand_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "import networkx.algorithms.community as nx_comm\n",
    "# from .generation import get_mean_cov, get_cor_from_cov, generate_samples_bag,␣ ↪set_zero_weights_to_very_low, get_corr_estimate, multivariate_t_rvs\n",
    "# from . import parallel\n",
    "#from matplotlib.pyplot import figure\n",
    "def get_true_labels(num_groups, num_members):\n",
    "    true_labels = np.zeros(num_groups * num_members, dtype=int)\n",
    "    for i in range(0, num_groups):\n",
    "        for j in range(0, num_members):\n",
    "            true_labels[i*num_members + j] = i\n",
    "            return true_labels\n",
    "        \n",
    "def get_partition(labels):\n",
    "    partition = []\n",
    "    for i in range(labels.max() + 1):\n",
    "        partition.append(np.where(labels == i)[0])\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rs_by_relation(r_out = 0.1, relation = np.linspace( 1, 10, 10)):\n",
    "    r_outs = np.full(relation.shape[0], r_out)\n",
    "    r_ins = np.array([x*r_out for x in relation])\n",
    "    return np.vstack((r_ins,r_outs))\n",
    "\n",
    "def get_rs_from_fixed_rin(r_in = 0.8, count_rout = 20, epsilon = 0):\n",
    "    r_ins = np.full(count_rout, r_in)\n",
    "    r_outs = np.linspace( 0, r_in + epsilon, count_rout)\n",
    "    return np.vstack((r_ins,r_outs))\n",
    "\n",
    "def get_rs_from_fixed_weighted_degree(degree=16, cluster_size= 20, num_clusters=2,r_out_bound = (0,1,20)):\n",
    "    #D = (N-1)D1 + (K-1)nD2\n",
    "    #D1= (D - (K-1)ND2)/(N-1)\n",
    "        #D2MAX > D/(KN - 1)\n",
    "    r_outs = np.linspace( r_out_bound[0], r_out_bound[1], r_out_bound[2])\n",
    "    r_outs = r_outs[r_outs <=degree/(num_clusters*cluster_size - 1)]\n",
    "    r_ins = (degree - (num_clusters - 1)*cluster_size*r_outs)/(cluster_size - 1)\n",
    "    return np.vstack((r_ins,r_outs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clustering(rs, algos, num_clusters = 2, cluster_size=5, sample_vol= 10, num_repeats = 200, corr_estimator=stats.pearsonr, distribution = np.random.multivariate_normal, **kwargs):\n",
    "    mean_covs = [get_mean_cov(num_clusters = num_clusters, cluster_size =cluster_size, r_in = rs[0][i], r_out = rs[1][i]) for i in range(rs.shape[1])]\n",
    "    means = [mean_cov[0] for mean_cov in mean_covs]\n",
    "    covs = [mean_cov[1] for mean_cov in mean_covs]\n",
    "    true_graphs = [get_cor_from_cov(cov) for cov in covs] \n",
    "    \n",
    "    [set_zero_weights_to_very_low(true_graph) for true_graph in true_graphs]\n",
    "\n",
    "    samples_bags = [generate_samples_bag(means[i], covs[i], bags = num_repeats, sample_size=sample_vol, distribution = distribution, **kwargs) for i,cov in enumerate(covs)]\n",
    "    print('Generating graphs started')\n",
    "    estimated_graphs_bags = [[set_zero_weights_to_very_low(get_corr_estimate(sample, corr_estimator)) for sample in samples_bag] for samples_bag in tqdm(samples_bags)]\n",
    "    print('Generating graphs complete')\n",
    "    \n",
    "    true_labels = get_true_labels(num_clusters, cluster_size)\n",
    "    result = dict()\n",
    "    for algo in algos:\n",
    "        algo_result = []\n",
    "        print(algo.__name__ + ' started')\n",
    "        for idx, estimated_graphs_bag in enumerate(tqdm(estimated_graphs_bags)):\n",
    "            repeat_result = []\n",
    "            for estimated_graph in estimated_graphs_bag:\n",
    "                repeat_result.append(algo(estimated_graph, num_clusters))\n",
    "            algo_result.append(repeat_result)\n",
    "        print(algo.__name__ + ' complete')\n",
    "        result[algo.__name__] = algo_result\n",
    "        \n",
    "    return true_labels, result, estimated_graphs_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_clustering_parallel(rs, algos, num_clusters = 2, cluster_size=5, sample_vol = 10, num_repeats = 200, corr_estimator=stats.pearsonr, distribution = np.random.multivariate_normal, **kwargs):\n",
    "#     mean_covs = [get_mean_cov(num_clusters = num_clusters, cluster_size = cluster_size, r_in = rs[0][i], r_out = rs[1][i]) for i in range(rs.shape[1])]\n",
    "#     means = [mean_cov[0] for mean_cov in mean_covs]\n",
    "#     covs = [mean_cov[1] for mean_cov in mean_covs]\n",
    "#     true_graphs = [get_cor_from_cov(cov) for cov in covs] \n",
    "#     [set_zero_weights_to_very_low(true_graph) for true_graph in true_graphs]\n",
    "#     samples_bags = [generate_samples_bag(means[i], covs[i], bags = num_repeats, sample_size=sample_vol, distribution = distribution, **kwargs) for i,cov in enumerate(covs)]\n",
    "#     print('Generating graphs started')\n",
    "#     estimated_graphs_bags = [[set_zero_weights_to_very_low(get_corr_estimate(sample, corr_estimator)) for sample in samples_bag] for samples_bag in tqdm(samples_bags)]\n",
    "#     estimated_graphs_bags = parallel.For()\n",
    "#     print('Generating graphs complete')\n",
    "#     true_labels = get_true_labels(num_clusters, cluster_size)\n",
    "#     result = dict()\n",
    "#     for algo in algos:\n",
    "#         algo_result = []\n",
    "#         print(algo.__name__ + ' started')\n",
    "#         for idx, estimated_graphs_bag in enumerate(tqdm(estimated_graphs_bags)):\n",
    "#             repeat_result = []\n",
    "#             for estimated_graph in estimated_graphs_bag:\n",
    "#                     repeat_result.append(algo(estimated_graph, num_clusters))\n",
    "#             algo_result.append(repeat_result)\n",
    "        \n",
    "#         print(algo.__name__ + ' complete')\n",
    "#         result[algo.__name__] = algo_result\n",
    "\n",
    "#     return true_labels, result, estimated_graphs_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct RGB color; the keyword argument name must be a standard mpl colormap name.\n",
    "    '''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "def nested_dict_to_dict(x):\n",
    "    y = dict()\n",
    "    for k1 in x:\n",
    "        for k2 in x[k1]:\n",
    "            y[(k1,k2)]=x[k1][k2]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_by_relation(rs, metrics, concrete_metrics=None, by_rin = True):\n",
    "        #figure(figsize=(10, 12), dpi=100)\n",
    "    fig, ax = plt.subplots()\n",
    "    colors = ['-b', '-r', '-g', '-y', '-p', '-c', '-m']\n",
    "    #if len(metrics) * len(list(metrics.values())[0]) > len(colors): reduced_metrics = nested_dict_to_dict(metrics)\n",
    "    #colors = get_cmap(len(reduced_metrics))\n",
    "    c=0\n",
    "    if by_rin:\n",
    "        r=rs[0] \n",
    "    else:\n",
    "        r=rs[1] \n",
    "        if(concrete_metrics):\n",
    "            for i, algo_metric in enumerate(reduced_metrics):\n",
    "                if algo_metric[1] is concrete_metrics:\n",
    "                    ax.plot(r, reduced_metrics[algo_metric], colors[c], label=algo_metric[1] + ' ' + algo_metric[0])\n",
    "                    c+=1\n",
    "                else:\n",
    "                    for i, algo_metric in enumerate(reduced_metrics):\n",
    "                        ax.plot(r, reduced_metrics[algo_metric], colors[c],label=algo_metric[1] + ' ' + algo_metric[0])\n",
    "                        c+= 1 #ax.axis('equal')#ax.axis('p_in')\n",
    "                leg = ax.legend() #plt.plot(p_ins[:len(metric)], metric) plt.ylabel('Metric value', size=10)\n",
    "                if by_rin:\n",
    "                    plt.xlabel('R_in', size=10)\n",
    "                    plt.title('R_out=' + str(rs[1][0]), size=14)\n",
    "                else:\n",
    "                    plt.xlabel('R_out', size=10) #plt.title('R_out=' + str(rs[0][1]), size=14)\n",
    "                    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(rs, true_labels, result, estimated_graphs_bags, by_rin = True):\n",
    "    metrics_by_algos = dict()\n",
    "    for algo in tqdm(result):\n",
    "        metrics = dict()\n",
    "        metrics['RI'] = [np.mean(np.array([rand_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['ARI'] = [np.mean(np.array([adjusted_rand_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['MI'] = [np.mean(np.array([mutual_info_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['AMI'] = [np.mean(np.array([adjusted_mutual_info_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        #metrics['modularity'] = [np.mean(np.array([nx_comm. ↪modularity(true_labels, get_partition(labels)) for labels in␣ ↪labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics_by_algos[algo] = metrics\n",
    "    plot_quality_by_relation(rs, metrics_by_algos, 'RI', by_rin)\n",
    "    plot_quality_by_relation(rs, metrics_by_algos, 'ARI', by_rin)\n",
    "    plot_quality_by_relation(rs, metrics_by_algos, 'MI', by_rin)\n",
    "    plot_quality_by_relation(rs, metrics_by_algos, 'AMI', by_rin)\n",
    "    return metrics_by_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(metrics, rs):\n",
    "    df= pd.DataFrame(nested_dict_to_dict(metrics))\n",
    "    df['r_in'] = rs[0]\n",
    "    df.set_index('r_in', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multivariate_t_rvs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_mixture\u001b[39m(r_in, r_out, algos, num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, cluster_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, sample_vol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, num_repeats \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m, corr_estimator\u001b[38;5;241m=\u001b[39mstats\u001b[38;5;241m.\u001b[39mpearsonr, distributions \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmultivariate_normal, \u001b[43mmultivariate_t_rvs\u001b[49m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      2\u001b[0m     mean, cov \u001b[38;5;241m=\u001b[39m get_mean_cov(num_clusters \u001b[38;5;241m=\u001b[39m num_clusters, cluster_size \u001b[38;5;241m=\u001b[39m cluster_size, r_in \u001b[38;5;241m=\u001b[39m r_in, r_out \u001b[38;5;241m=\u001b[39m r_out)\n\u001b[1;32m      3\u001b[0m     true_graph \u001b[38;5;241m=\u001b[39m get_cor_from_cov(cov)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multivariate_t_rvs' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_mixture(r_in, r_out, algos, num_clusters = 2, cluster_size=5, sample_vol = 10, num_repeats = 200, corr_estimator=stats.pearsonr, distributions = [np.random.multivariate_normal, multivariate_t_rvs], **kwargs):\n",
    "    mean, cov = get_mean_cov(num_clusters = num_clusters, cluster_size = cluster_size, r_in = r_in, r_out = r_out)\n",
    "    true_graph = get_cor_from_cov(cov)\n",
    "    set_zero_weights_to_very_low(true_graph)\n",
    "    distr1 = np.random.multivariate_normal#distributions[0]\n",
    "    distr2 = multivariate_t_rvs#distributions[1]\n",
    "    print(distr1)\n",
    "    samples_bag_distr1 = generate_samples_bag(mean, cov, bags = num_repeats, sample_size=sample_vol, distribution = distr1, **kwargs)\n",
    "    samples_bag_distr2 = generate_samples_bag(mean, cov, bags = num_repeats, sample_size=sample_vol, distribution = distr2, **kwargs)\n",
    "    print('Generating graphs started')\n",
    "    estimated_graphs_distr1 = [set_zero_weights_to_very_low(get_corr_estimate(sample, corr_estimator)) for sample in samples_bag_distr1]\n",
    "    estimated_graphs_distr2 = [set_zero_weights_to_very_low(get_corr_estimate(sample, corr_estimator)) for sample in samples_bag_distr2]\n",
    "    print('Generating graphs complete')\n",
    "    estimated_graphs_distrs = [estimated_graphs_distr1, estimated_graphs_distr2]\n",
    "    true_labels = get_true_labels(num_clusters, cluster_size)\n",
    "    result = dict()\n",
    "    eps = np.linspace( 0, 1, 100)\n",
    "    for algo in algos:\n",
    "        algo_result = []\n",
    "        print(algo.__name__ + ' started')\n",
    "        for ep in tqdm(eps):\n",
    "            repeat_result = []\n",
    "            for g1,g2 in zip(estimated_graphs_distr1, estimated_graphs_distr2):\n",
    "                g = g1\n",
    "                if int(np.random.binomial(1, 1 - ep, 1)[0]):\n",
    "                    g = g2\n",
    "                    repeat_result.append(algo(g, num_clusters))\n",
    "            algo_result.append(repeat_result)\n",
    "        print(algo.__name__ + ' complete')\n",
    "        result[algo.__name__] = algo_result\n",
    "        \n",
    "    return true_labels, result, estimated_graphs_distrs, eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_mixture(eps, metrics, concrete_metrics=None): #figure(figsize=(10, 12), dpi=100)\n",
    "    fig, ax = plt.subplots()\n",
    "    colors = ['-b', '-r', '-g', '-y', '-p', '-c', '-m']\n",
    "    #if len(metrics) * len(list(metrics.values())[0]) > len(colors): reduced_metrics = nested_dict_to_dict(metrics)\n",
    "    #colors = get_cmap(len(reduced_metrics))\n",
    "    c=0\n",
    "    if(concrete_metrics):\n",
    "        for i, algo_metric in enumerate(reduced_metrics):\n",
    "            if algo_metric[1] is concrete_metrics:\n",
    "                ax.plot(eps, reduced_metrics[algo_metric], colors[c], label=algo_metric[1] + ' ' + algo_metric[0])\n",
    "                c+=1\n",
    "    else:\n",
    "        for i, algo_metric in enumerate(reduced_metrics):\n",
    "            ax.plot(eps, reduced_metrics[algo_metric], colors[c], label=algo_metric[1] + ' ' + algo_metric[0])\n",
    "            c += 1 #ax.axis('equal')#ax.axis('p_in')\n",
    "    leg = ax.legend() #plt.plot(p_ins[:len(metric)], metric)\n",
    "    plt.ylabel('Metric value', size=10)\n",
    "    plt.xlabel('eps', size=10)\n",
    "    plt.title('Mixture uncertainty', size=14)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(true_labels, result, estimated_graphs_distrs, eps): \n",
    "    metrics_by_algos = dict()\n",
    "    for algo in tqdm(result):\n",
    "        metrics = dict()\n",
    "        metrics['RI'] = [np.mean(np.array([rand_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['ARI'] = [np.mean(np.array([adjusted_rand_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['MI'] = [np.mean(np.array([mutual_info_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics['AMI'] = [np.mean(np.array([adjusted_mutual_info_score(true_labels, labels) for labels in labels_repeated])) for labels_repeated in result[algo]]\n",
    "        #metrics['modularity'] = [np.mean(np.array([nx_comm. ↪modularity(true_labels, get_partition(labels)) for labels in␣ ↪labels_repeated])) for labels_repeated in result[algo]]\n",
    "        metrics_by_algos[algo] = metrics\n",
    "        plot_quality_mixture(eps, metrics_by_algos, 'ARI')\n",
    "        plot_quality_mixture(eps, metrics_by_algos, 'AMI')\n",
    "        return metrics_by_algos, eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow30_tickers = ['AXP', 'AMGN', 'AAPL', 'BA', 'CAT',\n",
    "                'CSCO', 'CVX', 'GS', 'HD', 'HON',\n",
    "                'IBM', 'INTC', 'JNJ', 'KO', 'JPM',\n",
    "                'MCD', 'MMM', 'MRK', 'MSFT', 'NKE',\n",
    "                 'PG', 'TRV', 'UNH', 'CRM', 'VZ',\n",
    "                'V', 'WBA', 'WMT', 'DIS', 'DOW']\n",
    "len(dow30_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  30 of 30 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "START_DATE  =\"2022-01-01\"\n",
    "END_DATE =\"2023-01-01\"\n",
    "data = yf.download(' '.join(dow30_tickers), start=START_DATE, end=END_DATE,\n",
    "                                 group_by='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th colspan=\"6\" halign=\"left\">CSCO</th>\n",
       "      <th colspan=\"4\" halign=\"left\">MSFT</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"4\" halign=\"left\">CVX</th>\n",
       "      <th colspan=\"6\" halign=\"left\">MRK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>...</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-04 00:00:00+00:00</th>\n",
       "      <td>-0.007340</td>\n",
       "      <td>-0.008561</td>\n",
       "      <td>-0.022491</td>\n",
       "      <td>-0.030707</td>\n",
       "      <td>-0.024832</td>\n",
       "      <td>0.546561</td>\n",
       "      <td>-0.001552</td>\n",
       "      <td>-0.008318</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>-0.017296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020005</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.426183</td>\n",
       "      <td>-0.002353</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.238297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05 00:00:00+00:00</th>\n",
       "      <td>-0.020222</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.014173</td>\n",
       "      <td>-0.015963</td>\n",
       "      <td>-0.015963</td>\n",
       "      <td>0.021181</td>\n",
       "      <td>-0.027155</td>\n",
       "      <td>-0.027615</td>\n",
       "      <td>-0.031586</td>\n",
       "      <td>-0.039144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019940</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>-0.058072</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.032343</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.375839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06 00:00:00+00:00</th>\n",
       "      <td>-0.019639</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.005659</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>-0.435362</td>\n",
       "      <td>-0.039786</td>\n",
       "      <td>-0.022862</td>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.007933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>-0.150853</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>-0.002886</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.000634</td>\n",
       "      <td>-0.429191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07 00:00:00+00:00</th>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.026947</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>-0.006927</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.061592</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.292057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10 00:00:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>-0.002475</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>0.204099</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>-0.005640</td>\n",
       "      <td>-0.017568</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>-0.114980</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>0.023562</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.025452</td>\n",
       "      <td>0.025452</td>\n",
       "      <td>0.255321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23 00:00:00+00:00</th>\n",
       "      <td>-0.005067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>-0.883631</td>\n",
       "      <td>-0.021577</td>\n",
       "      <td>-0.012977</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031346</td>\n",
       "      <td>0.030448</td>\n",
       "      <td>0.030448</td>\n",
       "      <td>0.054788</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>-0.610540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27 00:00:00+00:00</th>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.233406</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.008047</td>\n",
       "      <td>-0.007442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>-0.162371</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.119731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28 00:00:00+00:00</th>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>-0.005096</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>-0.203201</td>\n",
       "      <td>-0.007612</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>-0.010308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>-0.014862</td>\n",
       "      <td>-0.014863</td>\n",
       "      <td>-0.139654</td>\n",
       "      <td>0.004261</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>-0.009319</td>\n",
       "      <td>-0.009319</td>\n",
       "      <td>-0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29 00:00:00+00:00</th>\n",
       "      <td>-0.009057</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.146099</td>\n",
       "      <td>-0.005248</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>-0.081629</td>\n",
       "      <td>-0.013376</td>\n",
       "      <td>-0.010597</td>\n",
       "      <td>-0.002795</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>-0.002343</td>\n",
       "      <td>-0.134007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 00:00:00+00:00</th>\n",
       "      <td>0.000212</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>-0.006581</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.146895</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>-0.008135</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>-0.004950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.189254</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>-0.002510</td>\n",
       "      <td>-0.005705</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.207732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker                         CSCO                                          \\\n",
       "Price                          Open      High       Low     Close Adj Close   \n",
       "Date                                                                          \n",
       "2022-01-04 00:00:00+00:00 -0.007340 -0.008561 -0.022491 -0.030707 -0.024832   \n",
       "2022-01-05 00:00:00+00:00 -0.020222 -0.018803 -0.014173 -0.015963 -0.015963   \n",
       "2022-01-06 00:00:00+00:00 -0.019639 -0.008308 -0.005659  0.010561  0.010561   \n",
       "2022-01-07 00:00:00+00:00  0.014396  0.006034  0.012606  0.003441  0.003441   \n",
       "2022-01-10 00:00:00+00:00  0.000000  0.006483 -0.002475  0.011224  0.011224   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2022-12-23 00:00:00+00:00 -0.005067  0.000000  0.006830  0.003376  0.003376   \n",
       "2022-12-27 00:00:00+00:00  0.008850  0.004622  0.004457  0.001053  0.001052   \n",
       "2022-12-28 00:00:00+00:00  0.000419  0.001257 -0.005096 -0.009725 -0.009725   \n",
       "2022-12-29 00:00:00+00:00 -0.009057 -0.000628  0.005942  0.009094  0.009094   \n",
       "2022-12-30 00:00:00+00:00  0.000212 -0.001467 -0.006581  0.002943  0.002943   \n",
       "\n",
       "Ticker                                   MSFT                                \\\n",
       "Price                        Volume      Open      High       Low     Close   \n",
       "Date                                                                          \n",
       "2022-01-04 00:00:00+00:00  0.546561 -0.001552 -0.008318 -0.011160 -0.017296   \n",
       "2022-01-05 00:00:00+00:00  0.021181 -0.027155 -0.027615 -0.031586 -0.039144   \n",
       "2022-01-06 00:00:00+00:00 -0.435362 -0.039786 -0.022862 -0.014312 -0.007933   \n",
       "2022-01-07 00:00:00+00:00  0.026947  0.003188 -0.006927 -0.004505  0.000510   \n",
       "2022-01-10 00:00:00+00:00  0.204099 -0.014945 -0.005640 -0.017568  0.000732   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2022-12-23 00:00:00+00:00 -0.883631 -0.021577 -0.012977  0.000299  0.002265   \n",
       "2022-12-27 00:00:00+00:00  0.233406  0.010910  0.000251  0.008047 -0.007442   \n",
       "2022-12-28 00:00:00+00:00 -0.203201 -0.007612  0.003301 -0.007064 -0.010308   \n",
       "2022-12-29 00:00:00+00:00  0.146099 -0.005248  0.009136  0.006300  0.027255   \n",
       "2022-12-30 00:00:00+00:00  0.146895  0.010805 -0.008135  0.004277 -0.004950   \n",
       "\n",
       "Ticker                     ...       CVX                                \\\n",
       "Price                      ...       Low     Close Adj Close    Volume   \n",
       "Date                       ...                                           \n",
       "2022-01-04 00:00:00+00:00  ...  0.020005  0.018032  0.018032  0.426183   \n",
       "2022-01-05 00:00:00+00:00  ...  0.019940  0.006485  0.006485 -0.058072   \n",
       "2022-01-06 00:00:00+00:00  ... -0.003529  0.008473  0.008473 -0.150853   \n",
       "2022-01-07 00:00:00+00:00  ...  0.010712  0.014258  0.014258  0.061592   \n",
       "2022-01-10 00:00:00+00:00  ...  0.007374  0.000640  0.000640 -0.114980   \n",
       "...                        ...       ...       ...       ...       ...   \n",
       "2022-12-23 00:00:00+00:00  ...  0.031346  0.030448  0.030448  0.054788   \n",
       "2022-12-27 00:00:00+00:00  ...  0.021135  0.012492  0.012492 -0.162371   \n",
       "2022-12-28 00:00:00+00:00  ... -0.008321 -0.014862 -0.014863 -0.139654   \n",
       "2022-12-29 00:00:00+00:00  ...  0.004084  0.007543  0.007543 -0.081629   \n",
       "2022-12-30 00:00:00+00:00  ...  0.005926  0.006540  0.006540  0.189254   \n",
       "\n",
       "Ticker                          MRK                                          \\\n",
       "Price                          Open      High       Low     Close Adj Close   \n",
       "Date                                                                          \n",
       "2022-01-04 00:00:00+00:00 -0.002353  0.004280  0.007141  0.001820  0.001820   \n",
       "2022-01-05 00:00:00+00:00  0.011194  0.032343  0.017891  0.023992  0.023992   \n",
       "2022-01-06 00:00:00+00:00  0.019610 -0.002886  0.008891 -0.000634 -0.000634   \n",
       "2022-01-07 00:00:00+00:00  0.000888  0.011867  0.006521  0.018476  0.018476   \n",
       "2022-01-10 00:00:00+00:00  0.021080  0.023562  0.015304  0.025452  0.025452   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2022-12-23 00:00:00+00:00  0.003151  0.003932  0.005971  0.005558  0.005558   \n",
       "2022-12-27 00:00:00+00:00  0.010373  0.004094  0.005935  0.002322  0.002322   \n",
       "2022-12-28 00:00:00+00:00  0.004261  0.002661 -0.004223 -0.009319 -0.009319   \n",
       "2022-12-29 00:00:00+00:00 -0.013376 -0.010597 -0.002795 -0.002343 -0.002343   \n",
       "2022-12-30 00:00:00+00:00 -0.001437 -0.002510 -0.005705  0.001172  0.001172   \n",
       "\n",
       "Ticker                               \n",
       "Price                        Volume  \n",
       "Date                                 \n",
       "2022-01-04 00:00:00+00:00  0.238297  \n",
       "2022-01-05 00:00:00+00:00  0.375839  \n",
       "2022-01-06 00:00:00+00:00 -0.429191  \n",
       "2022-01-07 00:00:00+00:00  0.292057  \n",
       "2022-01-10 00:00:00+00:00  0.255321  \n",
       "...                             ...  \n",
       "2022-12-23 00:00:00+00:00 -0.610540  \n",
       "2022-12-27 00:00:00+00:00  0.119731  \n",
       "2022-12-28 00:00:00+00:00 -0.003518  \n",
       "2022-12-29 00:00:00+00:00 -0.134007  \n",
       "2022-12-30 00:00:00+00:00  0.207732  \n",
       "\n",
       "[250 rows x 180 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.apply(lambda x: np.log(x/x.shift(1)))\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(data.T)\n",
    "cov = set_zero_weights_to_very_low(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(col1, col2): \n",
    "    first1 = -1\n",
    "    first2 = -1\n",
    "    for i in range(len(col1)):\n",
    "        if col1[i] != 0 and first1 != -1:\n",
    "            first1 = i\n",
    "        if col2[i] != 0 and first2 != -1:\n",
    "            first2 = i\n",
    "\n",
    "    if first1 == 0 and first2 == 0:\n",
    "         return True\n",
    "#\n",
    "    first = max(first1, first2)\n",
    "    coeff = col1[first] / col2[first]\n",
    "    # -\n",
    "    # elem2 = elem1 * const\n",
    "    for i in range(len(col1)):\n",
    "        if abs(col1[i] - col2[i] * coeff) > 1e-10:\n",
    "                    return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_invertible(matrix):\n",
    "    n = len(matrix)\n",
    "    for i in range(n - 1):\n",
    "        for j in range(i + 1, n):\n",
    "            if check(matrix[i], matrix[j]):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "is_invertible(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectral_clustering</th>\n",
       "      <th>normalized_spectral_clustering</th>\n",
       "      <th>louvain</th>\n",
       "      <th>mst_cut_clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     spectral_clustering  normalized_spectral_clustering  louvain  \\\n",
       "0                      0                               0        0   \n",
       "1                      0                               0        0   \n",
       "2                      0                               0        0   \n",
       "3                      0                               0        2   \n",
       "4                      0                               0        2   \n",
       "..                   ...                             ...      ...   \n",
       "175                    0                               0        0   \n",
       "176                    0                               0        0   \n",
       "177                    0                               0        2   \n",
       "178                    0                               0        2   \n",
       "179                    1                               1        1   \n",
       "\n",
       "     mst_cut_clustering  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "..                  ...  \n",
       "175                   0  \n",
       "176                   0  \n",
       "177                   0  \n",
       "178                   0  \n",
       "179                   1  \n",
       "\n",
       "[180 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# КЛАСТЕРИЗАЦИЯ С РЕАЛЬНЫМИ ДАННЫМИ\n",
    "cor = get_cor_from_cov(cov)\n",
    "k=2\n",
    "algos = [spectral_clustering, normalized_spectral_clustering, louvain, mst_cut_clustering ]\n",
    "result = dict()\n",
    "for algo in algos:\n",
    "    result[algo.__name__] = algo(cor,k)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.generation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multivariate_t_rvs \n\u001b[1;32m      3\u001b[0m sample_vol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m\n\u001b[1;32m      4\u001b[0m distribution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmultivariate_normal \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.generation'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "from utils.generation import multivariate_t_rvs \n",
    "\n",
    "sample_vol = 250\n",
    "distribution = np.random.multivariate_normal \n",
    "mean = np.mean(data)\n",
    "distribution = multivariate_t_rvs\n",
    "samples = distribution(mean, cov, sample_vol).T\n",
    "esimated_cor = np.corrcoef(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'esimated_cor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m result_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo \u001b[38;5;129;01min\u001b[39;00m algos:\n\u001b[0;32m----> 5\u001b[0m     result_e[algo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m algo(\u001b[43mesimated_cor\u001b[49m,k)\n\u001b[1;32m      6\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(result)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'esimated_cor' is not defined"
     ]
    }
   ],
   "source": [
    "k=2\n",
    "algos = [spectral_clustering, normalized_spectral_clustering, louvain, mst_cut_clustering ]\n",
    "result_e = dict()\n",
    "for algo in algos:\n",
    "    result_e[algo.__name__] = algo(esimated_cor,k)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_uncertainty(cor, num_repeats, num_clusters, algos, distribution = np.random.multivariate_normal, **kwargs):\n",
    "    from utils.generation import generate_samples_bag\n",
    "    from sklearn.metrics.cluster import rand_score\n",
    "    #from sklearn.metrics import rand_score\n",
    "    from sklearn.metrics.cluster import adjusted_rand_score\n",
    "    from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "    from sklearn.metrics.cluster import mutual_info_score\n",
    "    result = dict()\n",
    "    sample_vol = 250\n",
    "    mean = np.mean(data)\n",
    "    samples_bag = generate_samples_bag(mean, cov, bags = num_repeats, sample_size=sample_vol, distribution = distribution, **kwargs)\n",
    "    estimated_graphs_bag = [set_zero_weights_to_very_low(np.corrcoef(sample)) for sample in samples_bag]\n",
    "   \n",
    "    true_labels = dict()\n",
    "    for algo in algos:\n",
    "        true_labels[algo.__name__] = algo(cor, num_clusters)\n",
    "        algo_result = []\n",
    "        for estimated_graph in estimated_graphs_bag:\n",
    "            algo_result.append(algo(estimated_graph, num_clusters))\n",
    "        result[algo.__name__] = algo_result\n",
    "    metrics_by_algos = dict()\n",
    "    for algo in result:\n",
    "        metrics = dict()\n",
    "        metrics['RI'] = np.array([rand_score(true_labels[algo], labels) for labels in result[algo]]).T\n",
    "        metrics['ARI'] = np.array([adjusted_rand_score(true_labels[algo], labels) for labels in result[algo]]).T\n",
    "        metrics_by_algos[algo] = metrics\n",
    "    return true_labels, result, estimated_graphs_bag, metrics_by_algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstock_uncertainty_different_k\u001b[39m(cor, num_repeats, ks, algos, distribution \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nested_dict_to_dict\n\u001b[1;32m      3\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distribution' is not defined"
     ]
    }
   ],
   "source": [
    "def stock_uncertainty_different_k(cor, num_repeats, ks, algos, distribution = distribution, **kwargs):\n",
    "    from utils.analyze import nested_dict_to_dict\n",
    "    metrics = dict()\n",
    "    for k in ks:\n",
    "        true_labels, result, estimated_graphs_bag, metrics[k] = stock_uncertainty(cor, num_repeats, k, algos, distribution = distribution, **kwargs)\n",
    "    for k in metrics:\n",
    "        for algo in metrics[k]:\n",
    "            for metric_type in metrics[k][algo]:\n",
    "                metrics[k][algo][metric_type] = np.mean(metrics[k][algo][metric_type])\n",
    "    metric_by_k = dict()\n",
    "    for k in metrics:\n",
    "        for algo in metrics[k]:\n",
    "            metric_by_k[algo] = dict()\n",
    "            for metric_type in metrics[k][algo]:\n",
    "                metric_by_k[algo][metric_type] = []\n",
    "    for k in metrics:\n",
    "        for algo in metrics[k]:\n",
    "            for metric_type in metrics[k][algo]:\n",
    "                metric_by_k[algo][metric_type].append(metrics[k][algo][metric_type])\n",
    "    df = pd.DataFrame(nested_dict_to_dict(metric_by_k), index = None)\n",
    "    df['k'] = ks\n",
    "    df.set_index('k', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.generation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m algos \u001b[38;5;241m=\u001b[39m [spectral_clustering, normalized_spectral_clustering, louvain, mst_cut_clustering ]\n\u001b[0;32m----> 2\u001b[0m true_labels, result, graphs, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mstock_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgos\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m, in \u001b[0;36mstock_uncertainty\u001b[0;34m(cor, num_repeats, num_clusters, algos, distribution, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstock_uncertainty\u001b[39m(cor, num_repeats, num_clusters, algos, distribution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmultivariate_normal, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_samples_bag\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rand_score\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#from sklearn.metrics import rand_score\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.generation'"
     ]
    }
   ],
   "source": [
    "algos = [spectral_clustering, normalized_spectral_clustering, louvain, mst_cut_clustering ]\n",
    "true_labels, result, graphs, metrics = stock_uncertainty(cor, 400, 2, algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.analyze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nested_dict_to_dict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.analyze'"
     ]
    }
   ],
   "source": [
    "from utils.analyze import nested_dict_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(nested_dict_to_dict(\u001b[43mmetrics\u001b[49m), index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(nested_dict_to_dict(metrics), index = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_uncertainty_different_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_by_k_normal \u001b[38;5;241m=\u001b[39m \u001b[43mstock_uncertainty_different_k\u001b[49m(cor, \u001b[38;5;241m400\u001b[39m, [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m], algos)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_uncertainty_different_k' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_normal = stock_uncertainty_different_k(cor, 400, [2,3,4,5,6,7], algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_uncertainty_different_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_by_k_student_df3 \u001b[38;5;241m=\u001b[39m \u001b[43mstock_uncertainty_different_k\u001b[49m(cor, \u001b[38;5;241m400\u001b[39m, [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m], algos, distribution\u001b[38;5;241m=\u001b[39mmultivariate_t_rvs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_uncertainty_different_k' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df3 = stock_uncertainty_different_k(cor, 400, [2,3,4,5,6,7], algos, distribution=multivariate_t_rvs, **{'df':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_student_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_by_k_student_df3\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_student_df3' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_by_k_normal\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_normal' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock_uncertainty_different_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_by_k_student_df2 \u001b[38;5;241m=\u001b[39m \u001b[43mstock_uncertainty_different_k\u001b[49m(cor, \u001b[38;5;241m400\u001b[39m, [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m], algos, distribution\u001b[38;5;241m=\u001b[39mmultivariate_t_rvs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m})\n\u001b[1;32m      2\u001b[0m metrics_by_k_student_df2\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stock_uncertainty_different_k' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df2 = stock_uncertainty_different_k(cor, 400, [2,3,4,5,6,7], algos, distribution=multivariate_t_rvs, **{'df':2})\n",
    "metrics_by_k_student_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_student_df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_by_k_student_df2\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_student_df2' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_student_df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_by_k_student_df2\u001b[49m \u001b[38;5;241m-\u001b[39m metrics_by_k_normal\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_student_df2' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df2 - metrics_by_k_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_normal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#metrics_by_k_student_df2[[col for col in metrics_by_k_student_df2.columns if␣ ↪'ARI' in col[-1]]]\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mmetrics_by_k_normal\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_df3\u001b[39m\u001b[38;5;124m'\u001b[39m: metrics_by_k_student_df3,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_df2\u001b[39m\u001b[38;5;124m'\u001b[39m:metrics_by_k_student_df2}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m      4\u001b[0m     metrics[name] \u001b[38;5;241m=\u001b[39m metrics[name][[col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m metrics[name]\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mARI\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m col[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_normal' is not defined"
     ]
    }
   ],
   "source": [
    "#metrics_by_k_student_df2[[col for col in metrics_by_k_student_df2.columns if␣ ↪'ARI' in col[-1]]]\n",
    "metrics = {'normal':metrics_by_k_normal, 'student_df3': metrics_by_k_student_df3,'student_df2':metrics_by_k_student_df2}\n",
    "for name in metrics:\n",
    "    metrics[name] = metrics[name][[col for col in metrics[name].columns if 'ARI' in col[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics_per_k \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex:\n\u001b[1;32m      3\u001b[0m     metrics_per_k[k] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({name:metrics[name]\u001b[38;5;241m.\u001b[39mloc[k] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m metrics})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_per_k = {}\n",
    "for k in list(metrics.values())[0].index:\n",
    "    metrics_per_k[k] = pd.DataFrame({name:metrics[name].loc[k] for name in metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_by_k_student_df3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_by_k_student_df3\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics_by_k_student_df3' is not defined"
     ]
    }
   ],
   "source": [
    "metrics_by_k_student_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_per_k\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "metrics_per_k[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_per_k\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "metrics_per_k[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics_per_k\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdiff()\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "metrics_per_k[7].T.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmetrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "metrics['normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetrics\u001b[49m: \n\u001b[1;32m      2\u001b[0m     metrics[name]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_distribution_overview.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "for name in metrics: \n",
    "    metrics[name].to_csv(f'{name}_distribution_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_per_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in metrics_per_k:\n",
    "    metrics_per_k[k].to_csv(f'detailed_view_per_{k}_clusters.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
