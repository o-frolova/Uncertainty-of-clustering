{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StocksReader import ReaderStocksData\n",
    "from src.correlation import CorrelationMeasurement\n",
    "from src.clustering_methods import ClusteringMethods\n",
    "from src.multivariate_distribution import MultivariateDistribution\n",
    "from src.CBM import CorrelationBlockModel\n",
    "import itertools\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2020-01-01\"\n",
    "end_date =   '2023-01-01'\n",
    "\n",
    "ReaderData = ReaderStocksData(\"./data/DataStocks/SP500\")\n",
    "DATA_OF_STOCKS, TICKERS = ReaderData.load_data(str(start_date), str(end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "selected_indices = random.sample(range(100), 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DATA_OF_STOCKS \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mDATA_OF_STOCKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mselected_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m TICKERS \u001b[38;5;241m=\u001b[39m [TICKERS[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m selected_indices]\n",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DATA_OF_STOCKS \u001b[38;5;241m=\u001b[39m [\u001b[43mDATA_OF_STOCKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m selected_indices]\n\u001b[1;32m      2\u001b[0m TICKERS \u001b[38;5;241m=\u001b[39m [TICKERS[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m selected_indices]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "DATA_OF_STOCKS = [DATA_OF_STOCKS[i] for i in selected_indices]\n",
    "TICKERS = [TICKERS[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the mean vector and covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_covariance_matrix(Stocks, tickers) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates the covariance matrix for the given list of stock objects.\n",
    "    Returns:\n",
    "    - pd.DataFrame: Covariance matrix.\n",
    "    \"\"\"\n",
    "    covariance_matrix = []\n",
    "    for stock_1 in Stocks:\n",
    "        covv = []\n",
    "        for stock_2 in Stocks:\n",
    "            covv.append(np.cov(stock_1.returns, stock_2.returns)[0, 1])\n",
    "        covariance_matrix.append(covv)\n",
    "\n",
    "    return pd.DataFrame(covariance_matrix, columns = tickers, index = tickers)\n",
    "\n",
    "\n",
    "def get_mean_vector(Stocks):\n",
    "    mean_vector = []\n",
    "    for stock in Stocks:\n",
    "        mean_vector.append(stock.returns.mean())\n",
    "    return np.array(mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cov_matrix = get_covariance_matrix(DATA_OF_STOCKS, TICKERS)\n",
    "true_mean_vec = get_mean_vector(DATA_OF_STOCKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_method = ClusteringMethods()\n",
    "correlation_method = CorrelationMeasurement()\n",
    "multivariate_distribution = MultivariateDistribution()\n",
    "correlation_block_model = CorrelationBlockModel()\n",
    "\n",
    "params = {\n",
    "    'clustering_method': [\n",
    "                          cluster_method.single_clustering, \n",
    "                          cluster_method.louvain_clustering,\n",
    "                          cluster_method.spectral_clustering,\n",
    "                          cluster_method.normalized_spectral_clustering\n",
    "                        ],\n",
    "    'correlation_network': [\n",
    "                            correlation_method.Pearson, \n",
    "                            correlation_method.Kendall,\n",
    "                            correlation_method.Fechner\n",
    "                        ],\n",
    "    'multivariate_distribution': [\n",
    "                            multivariate_distribution.normal_distribution, \n",
    "                            multivariate_distribution.student_distribution\n",
    "                        ],\n",
    "    'number_clusters': [2, 4, 6],\n",
    "    'sample_size_of_observations': [10, 20, 40, 60]\n",
    "}\n",
    "\n",
    "params_name = {\n",
    "    'clustering_method': [\n",
    "                          'single_clustering', \n",
    "                          'louvain_clustering',\n",
    "                          'spectral_clustering',\n",
    "                          'normalized_spectral_clustering'\n",
    "                        ],\n",
    "    'correlation_network': [\n",
    "                            'Pearson', \n",
    "                            'Kendall',\n",
    "                            'Fechner'\n",
    "                        ],\n",
    "    'multivariate_distribution': [\n",
    "                            'normal_distribution', \n",
    "                            'student_distribution'\n",
    "                        ],\n",
    "    'number_clusters': [2, 4, 6],\n",
    "    'sample_size_of_observations': [10, 20, 40, 60]\n",
    "\n",
    "}\n",
    "\n",
    "# Создание всех возможных комбинаций параметров\n",
    "keys, values = zip(*params.items())\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "\n",
    "keys_name, values_name = zip(*params_name.items())\n",
    "combinations_name = [dict(zip(keys_name, combination)) for combination in itertools.product(*values_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_experiment(cluster_method,\n",
    "                   correlation_method,\n",
    "                   multivariate_distribution,\n",
    "                   number_clusters,\n",
    "                   sample_size_of_observations,\n",
    "                   Stocks,\n",
    "                   true_cov_matrix,\n",
    "                   true_mean_vec,\n",
    ") -> float:\n",
    "   correlation_matrix = []\n",
    "   for stock_1 in Stocks:\n",
    "      row = []\n",
    "      for stock_2 in Stocks:\n",
    "         row.append(correlation_method(stock_1.returns, stock_2.returns))\n",
    "      correlation_matrix.append(row)\n",
    "   \n",
    "   true_labels = cluster_method(np.array(correlation_matrix), number_clusters)\n",
    "\n",
    "   gen_labels_ = correlation_block_model.clustering(multivariate_distribution = multivariate_distribution,\n",
    "                                                     mean_vector = true_mean_vec,\n",
    "                                                     cov_matrix = true_cov_matrix,\n",
    "                                                     sample_size_of_observations = sample_size_of_observations,\n",
    "                                                     correlation_method = correlation_method,\n",
    "                                                     clustering_method = cluster_method,\n",
    "                                                     number_clusters = number_clusters\n",
    "                                                     )\n",
    "\n",
    "   return adjusted_rand_score(true_labels, gen_labels_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                             \r"
     ]
    }
   ],
   "source": [
    "results_experiments = pd.DataFrame()\n",
    "number_repetitions = 100\n",
    "\n",
    "for combination, combination_name in tqdm(zip(combinations, combinations_name), leave=False):\n",
    "    ari_score_results = []\n",
    "    for count in range(number_repetitions):\n",
    "        result_score = one_experiment(cluster_method = combination['clustering_method'],\n",
    "                   correlation_method = combination['correlation_network'],\n",
    "                   multivariate_distribution = combination['multivariate_distribution'],\n",
    "                   number_clusters = combination['number_clusters'],\n",
    "                   sample_size_of_observations = combination['sample_size_of_observations'],\n",
    "                   Stocks = DATA_OF_STOCKS,\n",
    "                   true_cov_matrix = true_cov_matrix,\n",
    "                   true_mean_vec = true_mean_vec,\n",
    "                )\n",
    "        ari_score_results.append(result_score)\n",
    "    combination_name['ARI'] = np.mean(ari_score_results)\n",
    "    results_experiments = results_experiments._append(pd.Series(combination_name), ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_experiments.to_csv('./Russia_60_stocks_all_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clustering_method</th>\n",
       "      <th>correlation_network</th>\n",
       "      <th>multivariate_distribution</th>\n",
       "      <th>number_clusters</th>\n",
       "      <th>sample_size_of_observations</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_clustering</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>normal_distribution</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.044896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>single_clustering</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>normal_distribution</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.064168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>single_clustering</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>normal_distribution</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.121485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>single_clustering</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>normal_distribution</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.070888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>single_clustering</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>normal_distribution</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.071804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>normalized_spectral_clustering</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>student_distribution</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.198829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>normalized_spectral_clustering</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>student_distribution</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.033827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>normalized_spectral_clustering</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>student_distribution</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.064043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>normalized_spectral_clustering</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>student_distribution</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>0.118824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>normalized_spectral_clustering</td>\n",
       "      <td>Fechner</td>\n",
       "      <td>student_distribution</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.143293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  clustering_method correlation_network  \\\n",
       "0                 single_clustering             Pearson   \n",
       "1                 single_clustering             Pearson   \n",
       "2                 single_clustering             Pearson   \n",
       "3                 single_clustering             Pearson   \n",
       "4                 single_clustering             Pearson   \n",
       "..                              ...                 ...   \n",
       "283  normalized_spectral_clustering             Fechner   \n",
       "284  normalized_spectral_clustering             Fechner   \n",
       "285  normalized_spectral_clustering             Fechner   \n",
       "286  normalized_spectral_clustering             Fechner   \n",
       "287  normalized_spectral_clustering             Fechner   \n",
       "\n",
       "    multivariate_distribution  number_clusters  sample_size_of_observations  \\\n",
       "0         normal_distribution                2                           10   \n",
       "1         normal_distribution                2                           20   \n",
       "2         normal_distribution                2                           40   \n",
       "3         normal_distribution                2                           60   \n",
       "4         normal_distribution                4                           10   \n",
       "..                        ...              ...                          ...   \n",
       "283      student_distribution                4                           60   \n",
       "284      student_distribution                6                           10   \n",
       "285      student_distribution                6                           20   \n",
       "286      student_distribution                6                           40   \n",
       "287      student_distribution                6                           60   \n",
       "\n",
       "          ARI  \n",
       "0    0.044896  \n",
       "1    0.064168  \n",
       "2    0.121485  \n",
       "3    0.070888  \n",
       "4    0.071804  \n",
       "..        ...  \n",
       "283  0.198829  \n",
       "284  0.033827  \n",
       "285  0.064043  \n",
       "286  0.118824  \n",
       "287  0.143293  \n",
       "\n",
       "[288 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def convert_table(data: pd.DataFrame) -> None:\n",
    "    columns =  params_name['number_clusters']\n",
    "    rows = params_name['clustering_method']\n",
    "    for multi_distribution in params_name['multivariate_distribution']:\n",
    "        for corr_network in params_name['correlation_network']:\n",
    "            for size_samples in params_name['sample_size_of_observations']:\n",
    "\n",
    "                filtered_data = data[(data['correlation_network'] == corr_network) & \n",
    "                            (data['multivariate_distribution'] == multi_distribution) & \n",
    "                            (data['sample_size_of_observations'] == size_samples)]\n",
    "                \n",
    "                result = pd.DataFrame(index=list(rows), columns=list(columns))\n",
    "\n",
    "                for row in rows:\n",
    "                    for column in columns:\n",
    "                        ari_value = filtered_data[(filtered_data['clustering_method'] == row) & \n",
    "                                                (filtered_data['number_clusters'] == column)]['ARI']\n",
    "                        \n",
    "                        if not ari_value.empty:\n",
    "                            result.loc[row, column] = ari_value.iloc[0]\n",
    "                result.to_csv(f'./results/Russia/stocks_60/Russia_60_stocks_{multi_distribution}_{corr_network}_{str(size_samples)}.csv')\n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Russia_60_stocks_results.csv\")\n",
    "\n",
    "convert_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
